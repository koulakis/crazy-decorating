{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data with image generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_v3 import preprocess_input, decode_predictions, InceptionV3\n",
    "from keras.models import Sequential\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 128\n",
    "\n",
    "model = InceptionV3(weights='imagenet')\n",
    "\n",
    "intermediate_layer_model = Model(inputs=model.input, outputs=model.layers[311].output)\n",
    "\n",
    "x = intermediate_layer_model.output\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "transfer_model = Model(inputs=intermediate_layer_model.input, outputs=predictions)\n",
    "\n",
    "# train last cluster and dense layer\n",
    "for layer in transfer_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# can train more \n",
    "for i in range(311,313):\n",
    "    transfer_model.layers[i].trainable = True\n",
    "\n",
    "transfer_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# using checkpoints and early stopping on validation sample to prevent overfitting\n",
    "# best weight is saved to file_path\n",
    "checkpoints_filepath=\"../checkpoints/weights_base.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(checkpoints_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=2)\n",
    "callbacks_list = [checkpoint, early] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "target_size = (299, 299, 3)\n",
    "\n",
    "train_images_directory = '../data/train_images_readable/'\n",
    "validation_images_directory = '../data/validation_images_readable/'\n",
    "\n",
    "train_datagen = ImageDataGenerator()\n",
    "validation_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_images_directory, \n",
    "    target_size=target_size, \n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary') \n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_images_directory,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_epochs = 20\n",
    "\n",
    "transfer_model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1,\n",
    "    epochs=number_of_epochs,\n",
    "    use_multiprocessing=True,\n",
    "    max_queue_size=300,\n",
    "    workers=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best weights\n",
    "transfer_model.load_weights(checkpoints_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model prediction on test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(input_dir, size):\n",
    "    return [\n",
    "        [filename.split('.')[0].split('_')[1],\n",
    "         resize(\n",
    "             imread(os.path.join(input_dir, filename)), \n",
    "             size)] \n",
    "        for filename in os.listdir(input_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_images_list = load_images('../data/test_images_readable/', (299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_image_array = np.array(\n",
    "    [image[1] \n",
    "     for image in test_images_list\n",
    "     if image[1].shape[2] == 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_predictions = [\n",
    "    [x[0], transfer_model.predict(x[1].reshape([1, 299, 299, 3]))] \n",
    "    for x in test_images_list \n",
    "    if (len(x[1].shape) == 3 and x[1].shape[2] == 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_dict = dict([[int(x[0]), x[1]] for x in test_predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_or_1(x):\n",
    "    return test_predictions_dict[x].argmax() + 1 if x in test_predictions_dict.keys() else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([[i, predict_or_1(i)] for i in range(1, 12801)], columns=['id', 'predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('first-submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
